{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't receive frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from wrapper_vpgnet import WrapperVPGNet\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "#model_path = '/home/luben/csie5452-lane-detection/vpgnet_weights_136_8_10_50/vpgnet_epoch_20.pth'\n",
    "model_path = '/home/luben/csie5452-lane-detection/vpgnet_weights_1346_8_10_100_lr_1e-5/vpgnet_epoch_55.pth'\n",
    "vpgnet = WrapperVPGNet(model_path)\n",
    "\n",
    "video_path = '/home/luben/car-data/demo4.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "color_map_mat = np.zeros((19, 3), dtype=np.uint8)\n",
    "for i in range(0, 19):\n",
    "    if i == 1:\n",
    "        # lane_solid_white\n",
    "        color_map_mat[i] = (255, 255, 255)\n",
    "    elif i == 3:\n",
    "        # lane_double_white\n",
    "        color_map_mat[i] = (255, 255, 255)\n",
    "    elif i == 4:\n",
    "        # lane_solid_yellow\n",
    "        color_map_mat[i] = (0, 255, 255)\n",
    "    elif i == 6:\n",
    "        #lane_double_yellow\n",
    "        color_map_mat[i] = (0, 255, 255)\n",
    "    elif i == 18:\n",
    "        # erfnet_mask\n",
    "        color_map_mat[i] = (0, 0, 255)\n",
    "            \n",
    "def vpgnet_inference(image_origin):\n",
    "    \n",
    "    obj_mask_pred_160x120_vpgnet, vp_mask = vpgnet.get_lane_line_from_image_640x480(image_origin)\n",
    "    lane_solid_white = utils.resize_array(obj_mask_pred_160x120_vpgnet[0, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "    lane_double_white = utils.resize_array(obj_mask_pred_160x120_vpgnet[1, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "    lane_solid_yellow = utils.resize_array(obj_mask_pred_160x120_vpgnet[2, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "    lane_double_yellow = utils.resize_array(obj_mask_pred_160x120_vpgnet[3, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "\n",
    "    threshold = 0.95\n",
    "    lane_solid_white = np.where(lane_solid_white > threshold, 1, 0)\n",
    "    lane_double_white = np.where(lane_double_white > threshold, 1, 0)\n",
    "    lane_solid_yellow = np.where(lane_solid_yellow > threshold, 1, 0)\n",
    "    lane_double_yellow = np.where(lane_double_yellow > threshold, 1, 0)\n",
    "\n",
    "    \n",
    "    prob_map_lane_solid_white = lane_solid_white * 1\n",
    "    prob_map_lane_double_white = lane_double_white * 3\n",
    "    prob_map_lane_solid_yellow = lane_solid_yellow * 4\n",
    "    prob_map_lane_double_yellow = lane_double_yellow * 6\n",
    "\n",
    "    seg_image_lane_solid_white = color_map_mat[prob_map_lane_solid_white]\n",
    "    seg_image_lane_double_white = color_map_mat[prob_map_lane_double_white]\n",
    "    seg_image_lane_solid_yellow = color_map_mat[prob_map_lane_solid_yellow]\n",
    "    seg_image_lane_double_yellow = color_map_mat[prob_map_lane_double_yellow]\n",
    "\n",
    "    gamma = 0\n",
    "    img_lane_all = cv2.addWeighted(seg_image_lane_double_yellow, 1, seg_image_lane_solid_white, 1, gamma)\n",
    "    img_lane_all = cv2.addWeighted(seg_image_lane_solid_yellow, 1, img_lane_all, 1, gamma)\n",
    "    img_lane_all = cv2.addWeighted(seg_image_lane_double_white, 1, img_lane_all, 1, gamma)\n",
    "    img_lane_all = cv2.blur(img_lane_all, (9, 9))\n",
    "    img_lane_all = cv2.addWeighted(image_origin, 0.8, img_lane_all, 0.7, gamma)\n",
    "    \n",
    "    return img_lane_all\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        result_frame = vpgnet_inference(frame)\n",
    "        cv2.imshow('frame',result_frame)\n",
    "    if not ret:\n",
    "        print('can\\'t receive frame')\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VPGNet:\n\tsize mismatch for obj_mask.4.weight: copying a param with shape torch.Size([256, 3, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 4, 2, 2]).\n\tsize mismatch for obj_mask.4.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([4]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fd1e0c7abb79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/luben/csie5452-lane-detection/vpgnet_weights_136_8_10_50/vpgnet_epoch_20.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mvpgnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWrapperVPGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#image_origin = cv2.imread('demo/scene005.jpg', cv2.IMREAD_COLOR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimage_origin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/luben/car-data/car1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/csie5452-lane-detection/vpgnet-pytorch/wrapper_vpgnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVPGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# model = torch.load(model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vpgnet/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VPGNet:\n\tsize mismatch for obj_mask.4.weight: copying a param with shape torch.Size([256, 3, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 4, 2, 2]).\n\tsize mismatch for obj_mask.4.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([4])."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from wrapper_vpgnet import WrapperVPGNet\n",
    "import utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#model_path = '/home/luben/csie5452-lane-detection/vpgnet_weights/vpgnet_146_455_01.pth'\n",
    "model_path = '/home/luben/csie5452-lane-detection/vpgnet_weights_136_8_10_50/vpgnet_epoch_20.pth'\n",
    "\n",
    "vpgnet = WrapperVPGNet(model_path)\n",
    "#image_origin = cv2.imread('demo/scene005.jpg', cv2.IMREAD_COLOR)\n",
    "image_origin = cv2.imread('/home/luben/car-data/car1.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "copy_image_origin_vpgnet = cv2.resize(image_origin.copy(), (640, 480))\n",
    "obj_mask_pred_160x120_vpgnet, vp_mask = vpgnet.get_lane_line_from_image_640x480(copy_image_origin_vpgnet)\n",
    "\n",
    "\n",
    "\n",
    "# obj_mask_pred_1920x1080_vpgnet = np.resize(obj_mask_pred_160x120_vpgnet, (4, 1080, 1920))\n",
    "\n",
    "#lane_pred = utils.resize_array(obj_mask_pred_160x120_vpgnet[0, :, :], (939, 1921))\n",
    "lane_solid_white = utils.resize_array(obj_mask_pred_160x120_vpgnet[0, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "lane_double_white = utils.resize_array(obj_mask_pred_160x120_vpgnet[1, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "lane_double_yellow = utils.resize_array(obj_mask_pred_160x120_vpgnet[2, :, :], (image_origin.shape[0], image_origin.shape[1]))\n",
    "\n",
    "threshold = 0.95\n",
    "\n",
    "lane_solid_white = np.where(lane_solid_white > threshold, 1, 0)\n",
    "lane_double_white = np.where(lane_double_white > threshold, 1, 0)\n",
    "lane_double_yellow = np.where(lane_double_yellow > threshold, 1, 0)\n",
    "\n",
    "'''\n",
    "mask = cv2.imread('mask.jpg')\n",
    "#print(mask.shape)\n",
    "#print(mask.nonzero())\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(image_origin[:,:,::-1])\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "color_map_mat = np.zeros((19, 3), dtype=np.uint8)\n",
    "for i in range(0, 19):\n",
    "    if i == 1:\n",
    "        # lane_solid_white\n",
    "        color_map_mat[i] = (255, 255, 255)\n",
    "    elif i == 3:\n",
    "        # lane_double_white\n",
    "        color_map_mat[i] = (255, 255, 255)\n",
    "    elif i == 6:\n",
    "        #lane_double_yellow\n",
    "        color_map_mat[i] = (255, 255, 0)\n",
    "    elif i == 18:\n",
    "        # erfnet_mask\n",
    "        color_map_mat[i] = (0, 0, 255)\n",
    "\n",
    "prob_map_lane_solid_white = lane_solid_white * 1\n",
    "prob_map_lane_double_white = lane_double_white * 3\n",
    "prob_map_lane_double_yellow = lane_double_yellow * 6\n",
    "\n",
    "seg_image_lane_solid_white = color_map_mat[prob_map_lane_solid_white]\n",
    "seg_image_lane_double_white = color_map_mat[prob_map_lane_double_white]\n",
    "seg_image_lane_double_yellow = color_map_mat[prob_map_lane_double_yellow]\n",
    "\n",
    "gamma = 0\n",
    "img_lane_all = cv2.addWeighted(seg_image_lane_double_white, 1, seg_image_lane_solid_white, 1, gamma)\n",
    "img_lane_all = cv2.addWeighted(seg_image_lane_double_yellow, 1, img_lane_all, 1, gamma)\n",
    "img_lane_all = cv2.blur(img_lane_all, (9, 9))\n",
    "img_lane_all = cv2.addWeighted(image_origin[:,:,::-1], 0.8, img_lane_all, 0.7, gamma)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(img_lane_all)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lane_solid_white')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(lane_solid_white, cmap='gray')\n",
    "plt.show()\n",
    "print(lane_solid_white)\n",
    "print('lane_double_white')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(lane_double_white, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('lane_double_yellow')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(lane_double_yellow, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vanish point  (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_vp = 0.9999\n",
    "vp_mask_filter = np.where(vp_mask > threshold_vp, 1, 0)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(vp_mask_filter, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find lane line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minLineLength = 100\n",
    "maxLineGap = 10\n",
    "\n",
    "solid_white = lane_solid_white.copy().astype(np.uint8)\n",
    "double_white = lane_double_white.copy().astype(np.uint8)\n",
    "double_yellow = lane_double_yellow.copy().astype(np.uint8)\n",
    "\n",
    "lines_solid_white = cv2.HoughLinesP(solid_white, 1, np.pi / 180, 100, minLineLength, maxLineGap)\n",
    "lines_double_white = cv2.HoughLinesP(double_white, 1, np.pi / 180, 100, minLineLength, maxLineGap)\n",
    "lines_double_yellow = cv2.HoughLinesP(double_yellow, 1, np.pi / 180, 100, minLineLength, maxLineGap)\n",
    "\n",
    "image = img_lane_all.copy()\n",
    "\n",
    "if isinstance(lines_solid_white,np.ndarray):    \n",
    "    for x1, y1, x2, y2 in lines_solid_white[0]:\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 12)\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (255, 255, 255), 8)\n",
    "    '''\n",
    "    for x1, y1, x2, y2 in lines_solid_white[6]:\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 5)\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (255, 255, 255), 4)\n",
    "    '''\n",
    "'''\n",
    "if isinstance(lines_double_white,np.ndarray):\n",
    "    for x1, y1, x2, y2 in lines_double_white[0]:\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 5)\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "'''\n",
    "if isinstance(lines_double_yellow,np.ndarray):\n",
    "    for x1, y1, x2, y2 in lines_double_yellow[0]:\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 12)\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (230, 230, 0), 8)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = None\n",
    "for itm in [a,b]:\n",
    "    c= isinstance(itm,np.ndarray)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3,3, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.empty(3,3).random_(2)\n",
    "print(target)\n",
    "\n",
    "a = loss(m(input[0]), target[0])\n",
    "b = loss(m(input[1]), target[1])\n",
    "c = loss(m(input[2]), target[2])\n",
    "\n",
    "print(a,b,c)\n",
    "print((a+b+c)/3)\n",
    "output = loss(m(input), target)\n",
    "print(output)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
